# http 1.1 과 http 2.0 의 차이

## HTTP

- 웹 상에서 클라이언트와 서버 간 통신을 위한 프로토콜이다.
- HTTP 는 어플리케이션 계층에 속한다.
- 이론상으로는 http 커넥션이 신뢰성을 가지고 있다면 전송 계층에서 뭘 사용해도 상관없다.

## HTTP 의 무상태성

- HTTP 는 상태를 저장하지 않는다. 동일한 연결 상에서 연속하여 전달된 두 개의 요청 사이에는 연결고리가 없다.
- 그러면 어떻게, 특정 사용자가 해당 페이지와, 내가 이전 사용자임을 알려주며 상호작용 할 수 있을까?
- 이는 HTTP 쿠키 덕분이다. 쿠키는 상태가 있는 세션을 만들도록 해주고, 헤더를 사용하여 동일한 컨텍스트 또는 동일한 상태를 공유하기 위해 각각의 요청들에 세션을 만들도록 HTTP 쿠키가 추가된다.

## TCP (전송계층)

- 3 way handshake
- 연결 수립 후 데이터 전송 / 응답

## UDP (전송계층)

- 신뢰성을 별로 신경안씀
- 하지만 당연히 전송 속도가 TCP 에 비해 빠르다.

- HTTP 0.9 부터 2 버전까지는 기본적으로 TCP 전송 프로토콜을 사용한다.

### HTTP 1.0

- 헤더가 생김
- Content-Type 이 생겨서 html 외에도 다른 타입의 파일도 전송 할 수 있게됨
- 하나의 커넥션 당 1개의 요청 / 1 개의 응답 처리
- 하지만 매번 새로운 연결로 성능저하, 서버 부하 비용은 높아짐

### HTTP 1.1

- Persistant Connect : 1.0 의 문제점을 해결하기 위해서 지정한 타임아웃 동안 커넥션을 닫지 않는다.
- 파이프라이닝 기법 도입

#### 파이프라이닝이란?

- HTTP 는 순차적으로 메시지를 전송/응답 받아야함.
- 하나의 커넥션에서 응답을 기다리지 않고 순차적인 여러 요청을 연속적으로 보내 그 순서에 맞춰 응답을 받는 방식으로 지연 시간을 줄이는 방법이다.

#### 파이프라이닝의 치명적 단점 Head of Line Blocking

- 첫번째 요청이 왔는데 서버에서 처리하는 시간이 오래걸리면 두번째, 세번째 요청도 계속 기다려야하는것!

#### 헤더의 구조 중복 문제

### HTTP 2

- 성능향상에 초점을 맞춘 프로토콜

#### 메시지 전송 방식의 변화

- 바이너리 프레이밍 계층 사용
  - 파싱, 전송속도가 좋아짐
  - 오류 발생 가능성이 적어짐
- 응답/요청의 멀티플렉싱(다중화)가 가능해짐. 왜? 바이너리 프레임으로 쪼개졌기 때문에 메시지간 순서를 보장하지 않아도 된다. 그래서 Head of line Blocking 문제가 해결되었다.
- 리소스간 우선 순위를 설정 가능하다.
- 서버푸시 (클라이언트가 요청하지 않은 요청을 서버가 알아서 보내준다.)
- 헤더 압축 (헤더 크기를 줄여서 페이지 로드 시간을 감소시켰다.)

## HTTP/1.1 과 HTTP2의 차이점 (데이터 전송 방식)

- HTTP/1.1 과는 다르게 HTTP 2 는 모든 메시지를 이진 형식으로 캡슐화하는 동시에 verb, 메서드, 헤더 등의 HTTP 문법을 유지한다.
- 애플리케이션 layer api는 여전히 전통적인 HTTP 형식으로 메시지를 만들지만, 그 하단의 레이어는 이러한 메시지를 이진수로 변환한다. 이렇게 하면 HTTP/2 이전에 작성된 웹 애플리케이션이 새 프로토콜과 상호작용 할 때 정상적으로 작동할 수 있다
- 이진 형식으로 데이터를 전송하여, 파싱/전송 속도가 높아지고 오류발생 가능성이 적어졌다.

## HTTP1.1 과 HTTP2 의 차이점 TCP 커넥션

- HTTP/1.0에서는 클라이언트는 모든 새로운 요청을 위해 TCP 연결을 끊고 새로 연결을 만들어야 해서 시간과 리소스 측면에서 많은 비용이 들었다.
- HTTP/1.1은 영구적 연결(persistent connection)과 파이프라인을 도입하여 이 문제를 해결한다. 영구적인 연결을 사용하면 TCP 연결을 닫으라고 직접 요청하지 않는 이상 계속해서 연결을 열어둔다. 이를 통해 클라이언트는 동일한 연결을 통해 여러 요청의 각각의 응답을 기다리지 않고 전송할 수 있다.따라서 1.1에서 크게 성능이 향상되었다.
- 하지만 안타깝게도 이 최적화 전략에는 피할 수 없는 병목현상이 존재한다. 동일한 대상으로 이동할 때 여러 데이터 패킷이 동시에 통과할 수 없기 때문에, 대기열 앞에 있는 요청이 이후의 모든 요청이 차단되어 버린다. 이는 HOL (Head of line) 블로킹으로 알려져 있으며, HTTP/1.1에서 연결 효율성을 최적화 하는데 있어 중요한 문재다
- HTTP/2의 이진 프레임 레이어는 요청과 응답을 인코딩 하고 이를 더 작은 패킷으로 잘라 데이터 전송의 유연성을 향상 시킨다.
- , HTTP/2는 두 컴퓨터 사이에 단일 연결 개체를 설정한다. 이 연결에는 여러 데이터 스트림이 있다. 각 스트림은 요청/응답 형식의 여러메시지로 구성된다. 마지막으로 이러한 각 메시지는 프레임이라는 작은 단위로 분할 된다.
- HTTP2 에서는 프레임으로 쪼개졌기 때문에, 먼저 도착한게 먼저 조립해서 Head of Line Blocking 문제가해결되었다.

### Head of Line Blocking 문제란?

- 파이프라인에서 요청에 대한 응답을 처리하는데 앞에 있는 응답의 서버 처리 속도가 너무 느려서 클라이언트에 응답을 보내는 시간이 지연되는 현상.

## HTTP2 - 리소스 간 우선순위 설정 가능

- 스트림에 가중치를 줘서, 먼저 응답하게끔 설정 가능

## HTTP2 - 서버 푸시

- 클라이언트가 요청하지 않은 리소스를 서버가 알아서 전송해줄 수 있다.

## HTTP2 - 헤더 압축

- 헤더 크기를 줄여 페이지 로드 시간을 감소한다.
